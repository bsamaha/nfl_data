{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL macro trends report (1999–present)\n",
    "\n",
    "This notebook builds a league-wide view of offensive trends using your on-disk Parquet datasets:\n",
    "- Play-by-play: `data/silver/pbp`\n",
    "- Schedules (optional): `data/silver/schedules`\n",
    "\n",
    "It computes and visualizes:\n",
    "- Pace: plays per game, estimated seconds per play\n",
    "- Pass tendency and pass rate over expected (PROE)\n",
    "- Efficiency: EPA/play and success rate (overall, pass, rush)\n",
    "- Formations/tempo: shotgun rate, no-huddle rate\n",
    "- Passing depth: air yards\n",
    "- Environment effects: dome vs outdoors, and grass vs turf (points/game, EPA/play, explosive play rate)\n",
    "\n",
    "Outputs are saved to `reports/macro_trends/` for reuse in slides and docs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup\n",
    "Install and import analysis libraries used throughout the notebook. If your environment already has them, the install cell will no-op.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q pandas polars pyarrow duckdb matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: limit years for remote fallback\n",
    "If local parquet is missing, we’ll stream remote PBP files. You can limit years to speed things up by setting `NFL_YEARS` (e.g., `2015-2024`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a narrower range to speed up first run if desired\n",
    "# os.environ[\"NFL_YEARS\"] = \"2015-2024\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: materialize remote PBP to local Parquet\n",
    "To avoid re-downloading on every run, write the currently-selected years from `pbp` view to `data/silver/pbp/year=YYYY/`. Safe to skip if you prefer streaming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data connections\n",
    "We’ll register Parquet datasets as DuckDB views (`pbp`, `schedules`) for SQL-style queries without loading everything into memory. This supports incremental analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "BinderException",
     "evalue": "Binder Error: No function matches the given name and argument types 'read_parquet(VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR)'. You might need to add explicit type casts.\n\tCandidate functions:\n\tread_parquet(VARCHAR, can_have_nan : BOOLEAN, filename : ANY, union_by_name : BOOLEAN, debug_use_openssl : BOOLEAN, hive_partitioning : BOOLEAN, parquet_version : VARCHAR, encryption_config : ANY, hive_types_autocast : BOOLEAN, binary_as_string : BOOLEAN, explicit_cardinality : UBIGINT, compression : VARCHAR, file_row_number : BOOLEAN, hive_types : ANY, schema : ANY)\n\tread_parquet(VARCHAR[], can_have_nan : BOOLEAN, filename : ANY, union_by_name : BOOLEAN, debug_use_openssl : BOOLEAN, hive_partitioning : BOOLEAN, parquet_version : VARCHAR, encryption_config : ANY, hive_types_autocast : BOOLEAN, binary_as_string : BOOLEAN, explicit_cardinality : UBIGINT, compression : VARCHAR, file_row_number : BOOLEAN, hive_types : ANY, schema : ANY)\n\n\nLINE 3:         SELECT * FROM read_parquet('https://github.com/nflverse/nflverse-data...\n                              ^",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBinderException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m     files_sql = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mrepr\u001b[39m(u) \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m urls)\n\u001b[32m     37\u001b[39m     con.execute(\u001b[33m\"\u001b[39m\u001b[33mINSTALL httpfs; LOAD httpfs;\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m     39\u001b[39m \u001b[33;43m        CREATE OR REPLACE VIEW pbp AS\u001b[39;49m\n\u001b[32m     40\u001b[39m \u001b[33;43m        SELECT * FROM read_parquet(\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfiles_sql\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m);\u001b[39;49m\n\u001b[32m     41\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded remote PBP for years: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEARS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Schedules is optional; some fields like roof/surface may come from pbp already\u001b[39;00m\n",
      "\u001b[31mBinderException\u001b[39m: Binder Error: No function matches the given name and argument types 'read_parquet(VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR)'. You might need to add explicit type casts.\n\tCandidate functions:\n\tread_parquet(VARCHAR, can_have_nan : BOOLEAN, filename : ANY, union_by_name : BOOLEAN, debug_use_openssl : BOOLEAN, hive_partitioning : BOOLEAN, parquet_version : VARCHAR, encryption_config : ANY, hive_types_autocast : BOOLEAN, binary_as_string : BOOLEAN, explicit_cardinality : UBIGINT, compression : VARCHAR, file_row_number : BOOLEAN, hive_types : ANY, schema : ANY)\n\tread_parquet(VARCHAR[], can_have_nan : BOOLEAN, filename : ANY, union_by_name : BOOLEAN, debug_use_openssl : BOOLEAN, hive_partitioning : BOOLEAN, parquet_version : VARCHAR, encryption_config : ANY, hive_types_autocast : BOOLEAN, binary_as_string : BOOLEAN, explicit_cardinality : UBIGINT, compression : VARCHAR, file_row_number : BOOLEAN, hive_types : ANY, schema : ANY)\n\n\nLINE 3:         SELECT * FROM read_parquet('https://github.com/nflverse/nflverse-data...\n                              ^"
     ]
    }
   ],
   "source": [
    "# Imports and config\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb as ddb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "DATA_ROOT = Path(\"data/silver\")\n",
    "REPORT_DIR = Path(\"reports/macro_trends\")\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "con = ddb.connect()\n",
    "\n",
    "# Register Parquet datasets as views (with remote fallback if local parquet is missing)\n",
    "local_files = [p.as_posix() for p in (DATA_ROOT / \"pbp\").glob(\"**/*.parquet\")]\n",
    "if local_files:\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE OR REPLACE VIEW pbp AS\n",
    "        SELECT * FROM read_parquet('{(DATA_ROOT / \"pbp\" / \"**/*.parquet\").as_posix()}');\n",
    "    \"\"\")\n",
    "else:\n",
    "    years_env = os.getenv(\"NFL_YEARS\", \"1999-2024\")\n",
    "\n",
    "    def _parse_years_arg(years: str):\n",
    "        years = years.strip()\n",
    "        if \"-\" in years:\n",
    "            start, end = years.split(\"-\")\n",
    "            return list(range(int(start), int(end) + 1))\n",
    "        return [int(x) for x in years.split(\",\") if x.strip()]\n",
    "\n",
    "    YEARS = _parse_years_arg(years_env)\n",
    "    urls = [\n",
    "        f\"https://github.com/nflverse/nflverse-data/releases/download/pbp/play_by_play_{y}.parquet\"\n",
    "        for y in YEARS\n",
    "    ]\n",
    "    files_sql = \", \".join(repr(u) for u in urls)\n",
    "    con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE OR REPLACE VIEW pbp AS\n",
    "        SELECT * FROM read_parquet({files_sql});\n",
    "    \"\"\")\n",
    "    print(f\"Loaded remote PBP for years: {YEARS}\")\n",
    "\n",
    "# Schedules is optional; some fields like roof/surface may come from pbp already\n",
    "if (DATA_ROOT / \"schedules\").exists():\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE OR REPLACE VIEW schedules AS\n",
    "        SELECT * FROM read_parquet('{(DATA_ROOT / \"schedules\" / \"**/*.parquet\").as_posix()}');\n",
    "    \"\"\")\n",
    "else:\n",
    "    con.execute(\"CREATE OR REPLACE VIEW schedules AS SELECT NULL WHERE FALSE;\")\n",
    "\n",
    "print(\"Views ready: pbp, schedules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why we’re setting up these tables\n",
    "We’ll materialize season-level tables so downstream plotting is fast and reproducible. This keeps notebook runs quick even on large PBP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why we’re setting up these tables\n",
    "We’ll materialize season-level tables so downstream plotting is fast and reproducible. This keeps notebook runs quick even on large PBP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Season aggregates for macro trends\n",
    "CREATE OR REPLACE TABLE season_trends AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    season::INT AS season,\n",
    "    game_id,\n",
    "    -- pace proxies\n",
    "    COUNT(*) FILTER (WHERE play IN (1)) OVER (PARTITION BY season, game_id) AS plays_in_game,\n",
    "    -- pass/rush flags\n",
    "    pass::INT AS is_pass,\n",
    "    rush::INT AS is_rush,\n",
    "    -- tempo / formation\n",
    "    shotgun::INT AS is_shotgun,\n",
    "    no_huddle::INT AS is_no_huddle,\n",
    "    -- depth and efficiency\n",
    "    air_yards,\n",
    "    epa,\n",
    "    success::INT AS is_success,\n",
    "    -- environment\n",
    "    COALESCE(roof, game_stadium, stadium, '') AS roof_like,\n",
    "    surface\n",
    "  FROM pbp\n",
    "  WHERE season >= 1999 AND season_type = 'REG' AND play_deleted IS NULL\n",
    "), by_game AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    game_id,\n",
    "    SUM(1) AS plays,\n",
    "    SUM(is_pass) AS pass_plays,\n",
    "    SUM(is_rush) AS rush_plays,\n",
    "    AVG(is_shotgun) AS shotgun_rate,\n",
    "    AVG(is_no_huddle) AS no_huddle_rate,\n",
    "    AVG(NULLIF(air_yards, NULL)) AS mean_air_yards,\n",
    "    AVG(epa) AS epa_play,\n",
    "    AVG(CASE WHEN is_pass=1 THEN epa END) AS epa_pass,\n",
    "    AVG(CASE WHEN is_rush=1 THEN epa END) AS epa_rush,\n",
    "    AVG(is_success) AS success_rate,\n",
    "    AVG(CASE WHEN is_pass=1 THEN is_success END) AS pass_success,\n",
    "    AVG(CASE WHEN is_rush=1 THEN is_success END) AS rush_success,\n",
    "    AVG(CASE WHEN roof_like ILIKE '%dome%' OR roof_like ILIKE '%closed%' THEN 1 ELSE 0 END) AS is_dome,\n",
    "    CASE WHEN surface ILIKE '%turf%' OR surface ILIKE '%artificial%' THEN 'turf' ELSE 'grass' END AS surface_class\n",
    "  FROM base\n",
    "  GROUP BY season, game_id, surface_class\n",
    ")\n",
    "SELECT\n",
    "  season,\n",
    "  COUNT(DISTINCT game_id) AS games,\n",
    "  AVG(plays) AS avg_plays_per_game,\n",
    "  AVG(pass_plays::DOUBLE)/NULLIF(AVG(plays::DOUBLE),0) AS pass_rate,\n",
    "  AVG(shotgun_rate) AS shotgun_rate,\n",
    "  AVG(no_huddle_rate) AS no_huddle_rate,\n",
    "  AVG(mean_air_yards) AS air_yards,\n",
    "  AVG(epa_play) AS epa_play,\n",
    "  AVG(epa_pass) AS epa_pass,\n",
    "  AVG(epa_rush) AS epa_rush,\n",
    "  AVG(success_rate) AS success_rate,\n",
    "  AVG(pass_success) AS pass_success,\n",
    "  AVG(rush_success) AS rush_success\n",
    "FROM by_game\n",
    "GROUP BY season\n",
    "ORDER BY season;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we’re querying here\n",
    "Rebuild season-level aggregates to study:\n",
    "- Pace (plays/game, seconds/play)\n",
    "- Strategy (pass rate, xPass, PROE)\n",
    "- Formation/tempo (shotgun, no-huddle)\n",
    "- Efficiency (EPA/play, success rate, explosive rate)\n",
    "- Scoring (points/game)\n",
    "\n",
    "This block filters to true plays (play=1, non-deleted) in regular season.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use saved queries from `queries/`\n",
    "We’ll materialize season tables by executing the saved SQL files so the logic is reusable outside this notebook:\n",
    "- `queries/league/season_trends.sql`\n",
    "- `queries/league/season_environment_splits.sql`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Build season_trends from saved query\n",
    "CREATE OR REPLACE TABLE season_trends AS\n",
    "SELECT * FROM read_sql_file('queries/league/season_trends.sql');\n",
    "\n",
    "-- Build season_env_splits from saved query\n",
    "CREATE OR REPLACE TABLE season_env_splits AS\n",
    "SELECT * FROM read_sql_file('queries/league/season_environment_splits.sql');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Rebuild season trends with PROE and cleaner play filtering\n",
    "DROP TABLE IF EXISTS season_trends;\n",
    "\n",
    "CREATE TABLE season_trends AS\n",
    "WITH plays AS (\n",
    "  SELECT\n",
    "    season::INT AS season,\n",
    "    game_id,\n",
    "    play_id,\n",
    "    order_sequence,\n",
    "    pass::INT AS is_pass,\n",
    "    rush::INT AS is_rush,\n",
    "    shotgun::INT AS is_shotgun,\n",
    "    no_huddle::INT AS is_no_huddle,\n",
    "    air_yards,\n",
    "    epa,\n",
    "    success::INT AS is_success,\n",
    "    yards_gained,\n",
    "    xpass,\n",
    "    pass_oe,\n",
    "    COALESCE(roof, game_stadium, stadium, '') AS roof_like,\n",
    "    surface\n",
    "  FROM pbp\n",
    "  WHERE season >= 1999 AND season_type = 'REG' AND COALESCE(play_deleted,0)=0 AND play = 1\n",
    "), by_game AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    game_id,\n",
    "    COUNT(*) AS plays,\n",
    "    SUM(is_pass) AS pass_plays,\n",
    "    SUM(is_rush) AS rush_plays,\n",
    "    AVG(is_shotgun) AS shotgun_rate,\n",
    "    AVG(is_no_huddle) AS no_huddle_rate,\n",
    "    AVG(air_yards) AS air_yards,\n",
    "    AVG(epa) AS epa_play,\n",
    "    AVG(CASE WHEN is_pass=1 THEN epa END) AS epa_pass,\n",
    "    AVG(CASE WHEN is_rush=1 THEN epa END) AS epa_rush,\n",
    "    AVG(is_success) AS success_rate,\n",
    "    AVG(CASE WHEN is_pass=1 THEN is_success END) AS pass_success,\n",
    "    AVG(CASE WHEN is_rush=1 THEN is_success END) AS rush_success,\n",
    "    AVG(xpass) AS xpass,\n",
    "    AVG(pass_oe) AS pass_oe,\n",
    "    AVG(CASE WHEN yards_gained >= 20 THEN 1 ELSE 0 END) AS explosive_rate,\n",
    "    AVG(CASE WHEN roof_like ILIKE '%dome%' OR roof_like ILIKE '%closed%' THEN 1 ELSE 0 END) AS is_dome,\n",
    "    CASE WHEN surface ILIKE '%turf%' OR surface ILIKE '%artificial%' THEN 'turf' ELSE 'grass' END AS surface_class\n",
    "  FROM plays\n",
    "  GROUP BY season, game_id, surface_class\n",
    "), pace AS (\n",
    "  SELECT\n",
    "    p.season,\n",
    "    p.game_id,\n",
    "    MEDIAN(delta) FILTER (WHERE delta BETWEEN 0 AND 45) AS median_sec_per_play,\n",
    "    AVG(delta)    FILTER (WHERE delta BETWEEN 0 AND 45) AS mean_sec_per_play\n",
    "  FROM (\n",
    "    SELECT\n",
    "      season,\n",
    "      game_id,\n",
    "      order_sequence,\n",
    "      LAG(game_seconds_remaining) OVER (PARTITION BY season, game_id ORDER BY order_sequence) - game_seconds_remaining AS delta\n",
    "    FROM (\n",
    "      SELECT season, game_id, order_sequence, game_seconds_remaining\n",
    "      FROM pbp\n",
    "      WHERE season >= 1999 AND season_type='REG' AND COALESCE(play_deleted,0)=0 AND play=1\n",
    "    ) s\n",
    "  ) p\n",
    "  GROUP BY p.season, p.game_id\n",
    "), by_game_scoring AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    game_id,\n",
    "    MAX(total_home_score) + MAX(total_away_score) AS total_points\n",
    "  FROM pbp\n",
    "  WHERE season >= 1999 AND season_type='REG'\n",
    "  GROUP BY season, game_id\n",
    ")\n",
    "SELECT\n",
    "  g.season,\n",
    "  COUNT(DISTINCT g.game_id) AS games,\n",
    "  AVG(g.plays) AS avg_plays_per_game,\n",
    "  AVG(g.pass_plays::DOUBLE)/NULLIF(AVG(g.plays::DOUBLE),0) AS pass_rate,\n",
    "  AVG(g.shotgun_rate) AS shotgun_rate,\n",
    "  AVG(g.no_huddle_rate) AS no_huddle_rate,\n",
    "  AVG(g.air_yards) AS air_yards,\n",
    "  AVG(g.epa_play) AS epa_play,\n",
    "  AVG(g.epa_pass) AS epa_pass,\n",
    "  AVG(g.epa_rush) AS epa_rush,\n",
    "  AVG(g.success_rate) AS success_rate,\n",
    "  AVG(g.pass_success) AS pass_success,\n",
    "  AVG(g.rush_success) AS rush_success,\n",
    "  AVG(g.xpass) AS xpass,\n",
    "  AVG(g.pass_oe) AS pass_oe,\n",
    "  AVG(g.explosive_rate) AS explosive_rate,\n",
    "  AVG(p.median_sec_per_play) AS median_sec_per_play,\n",
    "  AVG(p.mean_sec_per_play) AS mean_sec_per_play,\n",
    "  AVG(s.total_points) AS points_per_game\n",
    "FROM by_game g\n",
    "LEFT JOIN pace p USING (season, game_id)\n",
    "LEFT JOIN by_game_scoring s USING (season, game_id)\n",
    "GROUP BY g.season\n",
    "ORDER BY g.season;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we’re querying here\n",
    "Compute per-season environment splits to answer:\n",
    "- Do domes increase scoring and efficiency vs outdoors?\n",
    "- Does turf elevate EPA/explosive rates vs grass?\n",
    "- Are these effects stable or changing over time?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Environment splits per season (dome vs outdoor, grass vs turf)\n",
    "CREATE OR REPLACE TABLE season_env_splits AS\n",
    "WITH plays AS (\n",
    "  SELECT\n",
    "    season::INT AS season,\n",
    "    game_id,\n",
    "    pass::INT AS is_pass,\n",
    "    rush::INT AS is_rush,\n",
    "    epa,\n",
    "    success::INT AS is_success,\n",
    "    yards_gained,\n",
    "    COALESCE(roof, game_stadium, stadium, '') AS roof_like,\n",
    "    surface\n",
    "  FROM pbp\n",
    "  WHERE season >= 1999 AND season_type = 'REG' AND COALESCE(play_deleted,0)=0 AND play=1\n",
    "), by_game AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    game_id,\n",
    "    AVG(CASE WHEN roof_like ILIKE '%dome%' OR roof_like ILIKE '%closed%' THEN 1 ELSE 0 END) AS is_dome,\n",
    "    CASE WHEN surface ILIKE '%turf%' OR surface ILIKE '%artificial%' THEN 'turf' ELSE 'grass' END AS surface_class,\n",
    "    COUNT(*) AS plays,\n",
    "    AVG(epa) AS epa_play,\n",
    "    AVG(CASE WHEN is_pass=1 THEN epa END) AS epa_pass,\n",
    "    AVG(CASE WHEN is_rush=1 THEN epa END) AS epa_rush,\n",
    "    AVG(is_success) AS success_rate,\n",
    "    AVG(CASE WHEN yards_gained >= 20 THEN 1 ELSE 0 END) AS explosive_rate\n",
    "  FROM plays\n",
    "  GROUP BY season, game_id, surface_class\n",
    "), by_game_scoring AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    game_id,\n",
    "    MAX(total_home_score) + MAX(total_away_score) AS total_points\n",
    "  FROM pbp\n",
    "  WHERE season >= 1999 AND season_type='REG'\n",
    "  GROUP BY season, game_id\n",
    ")\n",
    "SELECT\n",
    "  season,\n",
    "  CASE WHEN is_dome >= 0.5 THEN 'dome' ELSE 'outdoor' END AS roof_class,\n",
    "  surface_class,\n",
    "  COUNT(*) AS games,\n",
    "  AVG(plays) AS plays_per_game,\n",
    "  AVG(epa_play) AS epa_play,\n",
    "  AVG(epa_pass) AS epa_pass,\n",
    "  AVG(epa_rush) AS epa_rush,\n",
    "  AVG(success_rate) AS success_rate,\n",
    "  AVG(explosive_rate) AS explosive_rate,\n",
    "  AVG(s.total_points) AS points_per_game\n",
    "FROM by_game g\n",
    "LEFT JOIN by_game_scoring s USING (season, game_id)\n",
    "GROUP BY season, roof_class, surface_class\n",
    "ORDER BY season, roof_class, surface_class;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we’ll visualize next\n",
    "We’ll chart key macro trends and save shareable outputs:\n",
    "- Pace: plays/game and median seconds/play (are teams going faster?)\n",
    "- Strategy: pass rate, xPass, PROE; shotgun and no-huddle usage\n",
    "- Efficiency: EPA/play (overall/pass/rush) and points/game\n",
    "- Then compare environment splits (dome vs outdoor, turf vs grass) over the last 10 seasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results and plot/save key trends\n",
    "st = con.execute(\"SELECT * FROM season_trends ORDER BY season\").pl()\n",
    "se = con.execute(\n",
    "    \"SELECT * FROM season_env_splits ORDER BY season, roof_class, surface_class\"\n",
    ").pl()\n",
    "\n",
    "st_pd = st.to_pandas()\n",
    "se_pd = se.to_pandas()\n",
    "\n",
    "# Save CSVs for reuse\n",
    "st_pd.to_csv(REPORT_DIR / \"season_trends.csv\", index=False)\n",
    "se_pd.to_csv(REPORT_DIR / \"season_env_splits.csv\", index=False)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(14, 12), constrained_layout=True)\n",
    "\n",
    "# Pace and pass rate\n",
    "sns.lineplot(ax=axs[0, 0], data=st_pd, x=\"season\", y=\"avg_plays_per_game\", marker=\"o\")\n",
    "axs[0, 0].set_title(\"Plays per game\")\n",
    "\n",
    "sns.lineplot(ax=axs[0, 1], data=st_pd, x=\"season\", y=\"median_sec_per_play\", marker=\"o\")\n",
    "axs[0, 1].invert_yaxis()\n",
    "axs[0, 1].set_title(\"Median seconds per play (lower = faster)\")\n",
    "\n",
    "# Strategy\n",
    "sns.lineplot(\n",
    "    ax=axs[1, 0], data=st_pd, x=\"season\", y=\"pass_rate\", marker=\"o\", label=\"Pass rate\"\n",
    ")\n",
    "sns.lineplot(ax=axs[1, 0], data=st_pd, x=\"season\", y=\"xpass\", marker=\"o\", label=\"xPass\")\n",
    "sns.lineplot(\n",
    "    ax=axs[1, 0], data=st_pd, x=\"season\", y=\"pass_oe\", marker=\"o\", label=\"PROE\"\n",
    ")\n",
    "axs[1, 0].set_title(\"Pass tendency (rate/xPass/PROE)\")\n",
    "axs[1, 0].legend()\n",
    "\n",
    "sns.lineplot(\n",
    "    ax=axs[1, 1], data=st_pd, x=\"season\", y=\"shotgun_rate\", marker=\"o\", label=\"Shotgun\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=axs[1, 1],\n",
    "    data=st_pd,\n",
    "    x=\"season\",\n",
    "    y=\"no_huddle_rate\",\n",
    "    marker=\"o\",\n",
    "    label=\"No-huddle\",\n",
    ")\n",
    "axs[1, 1].set_title(\"Formation/tempo usage\")\n",
    "axs[1, 1].legend()\n",
    "\n",
    "# Efficiency\n",
    "sns.lineplot(\n",
    "    ax=axs[2, 0], data=st_pd, x=\"season\", y=\"epa_play\", marker=\"o\", label=\"EPA/play\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=axs[2, 0], data=st_pd, x=\"season\", y=\"epa_pass\", marker=\"o\", label=\"EPA/pass\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=axs[2, 0], data=st_pd, x=\"season\", y=\"epa_rush\", marker=\"o\", label=\"EPA/rush\"\n",
    ")\n",
    "axs[2, 0].set_title(\"Efficiency over time\")\n",
    "axs[2, 0].legend()\n",
    "\n",
    "sns.lineplot(ax=axs[2, 1], data=st_pd, x=\"season\", y=\"points_per_game\", marker=\"o\")\n",
    "axs[2, 1].set_title(\"Points per game\")\n",
    "\n",
    "plt.suptitle(\"NFL macro trends (1999–present)\", y=1.02)\n",
    "plt.savefig(REPORT_DIR / \"macro_trends_overview.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Environment comparison recent 10 seasons\n",
    "recent = se_pd[se_pd[\"season\"] >= (se_pd[\"season\"].max() - 9)]\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8), constrained_layout=True)\n",
    "\n",
    "sns.lineplot(\n",
    "    ax=axs[0, 0],\n",
    "    data=recent[recent[\"roof_class\"] == \"dome\"],\n",
    "    x=\"season\",\n",
    "    y=\"points_per_game\",\n",
    "    label=\"Dome\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=axs[0, 0],\n",
    "    data=recent[recent[\"roof_class\"] == \"outdoor\"],\n",
    "    x=\"season\",\n",
    "    y=\"points_per_game\",\n",
    "    label=\"Outdoor\",\n",
    ")\n",
    "axs[0, 0].set_title(\"Points per game: dome vs outdoor\")\n",
    "axs[0, 0].legend()\n",
    "\n",
    "sns.lineplot(\n",
    "    ax=axs[0, 1],\n",
    "    data=recent[recent[\"roof_class\"] == \"dome\"],\n",
    "    x=\"season\",\n",
    "    y=\"epa_play\",\n",
    "    label=\"Dome\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=axs[0, 1],\n",
    "    data=recent[recent[\"roof_class\"] == \"outdoor\"],\n",
    "    x=\"season\",\n",
    "    y=\"epa_play\",\n",
    "    label=\"Outdoor\",\n",
    ")\n",
    "axs[0, 1].set_title(\"EPA/play: dome vs outdoor\")\n",
    "axs[0, 1].legend()\n",
    "\n",
    "sns.lineplot(\n",
    "    ax=axs[1, 0],\n",
    "    data=recent[recent[\"surface_class\"] == \"turf\"],\n",
    "    x=\"season\",\n",
    "    y=\"points_per_game\",\n",
    "    label=\"Turf\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=axs[1, 0],\n",
    "    data=recent[recent[\"surface_class\"] == \"grass\"],\n",
    "    x=\"season\",\n",
    "    y=\"points_per_game\",\n",
    "    label=\"Grass\",\n",
    ")\n",
    "axs[1, 0].set_title(\"Points per game: turf vs grass\")\n",
    "axs[1, 0].legend()\n",
    "\n",
    "sns.lineplot(\n",
    "    ax=axs[1, 1],\n",
    "    data=recent[recent[\"surface_class\"] == \"turf\"],\n",
    "    x=\"season\",\n",
    "    y=\"epa_play\",\n",
    "    label=\"Turf\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=axs[1, 1],\n",
    "    data=recent[recent[\"surface_class\"] == \"grass\"],\n",
    "    x=\"season\",\n",
    "    y=\"epa_play\",\n",
    "    label=\"Grass\",\n",
    ")\n",
    "axs[1, 1].set_title(\"EPA/play: turf vs grass\")\n",
    "axs[1, 1].legend()\n",
    "\n",
    "plt.savefig(REPORT_DIR / \"environment_comparisons.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "st.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested interpretations for Best Ball strategy\n",
    "\n",
    "- Faster pace (lower seconds/play and higher plays/game) increases weekly spike potential. Stack teams that rank top-10 in pace and no-huddle usage.\n",
    "- Higher PROE and shotgun rates correlate with higher passing volume variance. Lean into WR-heavy builds when macro pass tendency is rising.\n",
    "- Dome advantage: if dome splits consistently show higher points/EPA, prioritize dome WR/QB for playoff weeks and draft tiebreakers.\n",
    "- Turf vs grass: if turf shows higher points/epa/explosive rate, mildly boost deep-threat WRs and K/QB in those environments.\n",
    "- Air yards trend: rising air yards supports spike-week WR archetypes; falling trend supports RB/TE floor builds.\n",
    "- Keep playoff weeks (Weeks 15-17) in mind. Prefer players on teams with dome home games or favorable late-season surfaces.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
